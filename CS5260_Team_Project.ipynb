{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnpgwiKxwvuv"
   },
   "source": [
    "# Project : Generating faces to remove mask on photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install opencv-python pyunpack scikit-image pillow==5.3.0\n",
    "%reload_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GORbKKI0weMY"
   },
   "source": [
    "## I - Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUKGk-5GxBw8"
   },
   "source": [
    "## II - GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8IrvEkRGwvgH"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pyunpack import Archive\n",
    "from tensorflow import keras \n",
    "from keras.utils.data_utils import Sequence\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, Dropout, Flatten, Reshape, Dense, add\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import random, math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "sN53ZtjLbYa0"
   },
   "outputs": [],
   "source": [
    "masks = [f\"./training_set_small/001_Combined_masked/{str(i).rjust(5,'0')}_N95.png\" for i in range(2000,4000)]\n",
    "nomasks = [f\"./training_set_small/001_Combined_original/{str(i).rjust(5,'0')}.png\" for i in range(2000,4000)]\n",
    "\n",
    "\n",
    "masks = []\n",
    "nomasks = []\n",
    "\n",
    "directory = './converted_256'\n",
    "parent_dir = os.listdir(directory)\n",
    "for subdir in parent_dir:   \n",
    "    if (not os.path.isdir(directory + \"/\"+ subdir)):\n",
    "        continue\n",
    "    is_mask = not subdir.endswith(\"unmasked\")\n",
    "    # print(len(os.listdir(directory + \"/\" + subdir)))\n",
    "    for files in os.listdir(directory + \"/\" + subdir):\n",
    "        if (not files.endswith(\".png\")):\n",
    "            continue\n",
    "        if (is_mask):\n",
    "            masks.append(directory + \"/\" + subdir  + \"/\" + files)\n",
    "        else:\n",
    "            nomasks.append(directory + \"/\" + subdir  + \"/\" + files)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9955\n",
      "9955\n"
     ]
    }
   ],
   "source": [
    "print(len(nomasks))\n",
    "print(len(masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "UWTN4ukrbaGq"
   },
   "outputs": [],
   "source": [
    "class Daugmentation:\n",
    "    def flip(img, t):\n",
    "        if t[0]==0:\n",
    "            return img\n",
    "        else:\n",
    "            return cv2.flip(img, t[1])\n",
    "\n",
    "    def zoom(img, t):\n",
    "        if t[2]==0:\n",
    "            return img\n",
    "        else:\n",
    "            h, w = img.shape[:2]\n",
    "            nh, nw =  int(t[3]*h), int(t[3]*w)\n",
    "            dh, dw = h-nh, w-nw\n",
    "            zimg = img[dh//2:nh+dh//2, dw//2:nw+dw//2]\n",
    "            zimg = cv2.resize(zimg, (w,h))\n",
    "            return zimg\n",
    "\n",
    "\n",
    "    def get_ts(batch_size):\n",
    "        return [[random.choice([0,1]),random.choice([-1,0,1]), random.randint(0,2),random.uniform(0.4,0.9)] for i in range(batch_size)]\n",
    "\n",
    "    def aug(img,t):\n",
    "        img = Daugmentation.flip(img,t)\n",
    "        # img = Daugmentation.zoom(img, t)\n",
    "        return img\n",
    "\n",
    "\n",
    "class maSequence(Sequence):\n",
    "    # x and y should store the file location\n",
    "    def __init__(self, x_set, y_set, batch_size, Daugmentation):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = Daugmentation\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get the filename\n",
    "        batch_x_filename = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y_filename = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "\n",
    "        # load the file\n",
    "        batch_x, batch_y = [], []\n",
    "        TARGET_SIZE = 256\n",
    "        for filename in tqdm(batch_x_filename, desc=\"loading train_data batch\"):\n",
    "            print('filename' ,filename)\n",
    "            batch_x.append(np.array(load_img(filename, target_size=(TARGET_SIZE, TARGET_SIZE))))\n",
    "            \n",
    "        for filename in tqdm(batch_y_filename, desc=\"loading train_label batch\"):\n",
    "            batch_y.append(np.array(load_img(filename, target_size=(TARGET_SIZE, TARGET_SIZE))))\n",
    "        batch_x, batch_y = np.array(batch_x), np.array(batch_y)\n",
    "        \n",
    "        ts = self.augment.get_ts(len(batch_x))\n",
    "        \n",
    "        return np.array([self.augment.aug(x,t) for x,t in zip(batch_x,ts)]),np.array([self.augment.aug(y,t) for y,t in zip(batch_y,ts)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "5HxxPCXPbigS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 34379.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((9,), (9,), (1,), (1,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "X = []\n",
    "Y = []\n",
    "test = []\n",
    "for i in tqdm(zip(masks, nomasks)):\n",
    "    # print(i[0])\n",
    "    try:\n",
    "        # img = load_img(i[0], target_size=(128,128))\n",
    "        X.append(i[0])\n",
    "        # img = load_img(i[1], target_size=(128,128))\n",
    "        Y.append(i[1])\n",
    "\n",
    "    except Exception as e: \n",
    "        # print(e)\n",
    "        continue\n",
    "\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "print(len(X),len(Y))\n",
    "np.random.seed(777)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.1)\n",
    "x_train.shape,y_train.shape, x_test.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.tensor(x_train).view(-1,3,128,128).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "lrX7LtQ1bl_T"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype <U47 cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4h/ngfg08zd7_52cd0t57x6dl84k2nxsw/T/ipykernel_31332/2404743746.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnomasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OFF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearn_course/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2651\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2652\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearn_course/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearn_course/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearn_course/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearn_course/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5626\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearn_course/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    692\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[1;32m    693\u001b[0m             raise TypeError(\"Image data of dtype {} cannot be converted to \"\n\u001b[0;32m--> 694\u001b[0;31m                             \"float\".format(self._A.dtype))\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         if not (self._A.ndim == 2\n",
      "\u001b[0;31mTypeError\u001b[0m: Image data of dtype <U47 cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "masks = x_test[:10]\n",
    "nomasks = y_test[:10]\n",
    "for i, (x,y) in enumerate(zip(masks[:10],nomasks[:10])):\n",
    "    plt.subplot(2,10,i+1)\n",
    "    plt.imshow(x)\n",
    "    plt.axis(\"OFF\")\n",
    "    \n",
    "    plt.subplot(2,10,i+11)\n",
    "    plt.imshow(y)\n",
    "    plt.axis(\"OFF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "Ijut4QdAvq50"
   },
   "outputs": [],
   "source": [
    "# Generator Code\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # First\n",
    "        \n",
    "        self.c1_1 = nn.Conv2d(3, 32, kernel_size = 3, padding = \"same\")\n",
    "        self.c1_2 = nn.Conv2d(32, 32, kernel_size = 3, padding = \"same\")\n",
    "        self.m1 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.c2_1 = nn.Conv2d(32, 64, 3, padding = \"same\")\n",
    "        self.c2_2 = nn.Conv2d(64, 64, 3, padding = \"same\")\n",
    "        self.m2 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.c3_1 = nn.Conv2d(64, 128, 3, padding = \"same\")\n",
    "        self.c3_2 = nn.Conv2d(128, 128, 3, padding = \"same\")\n",
    "        self.m3 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.c4_1 = nn.Conv2d(128, 256, 3, padding = \"same\")\n",
    "        self.c4_2 = nn.Conv2d(256, 256, 3, padding = \"same\")\n",
    "\n",
    "\n",
    "        self.u1 = nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1)\n",
    "        self.c5_1 = nn.ConvTranspose2d(128,128, 3, padding = 1)\n",
    "        self.c5_2 = nn.ConvTranspose2d(128,128, 3, padding = 1)\n",
    "\n",
    "        self.u2 = nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1)\n",
    "        self.c6_1 = nn.ConvTranspose2d(64, 64, 3, padding = 1)\n",
    "        self.c6_2 = nn.ConvTranspose2d(64, 64, 3, padding = 1)\n",
    "\n",
    "        self.u3 = nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1)\n",
    "        self.c7_1 = nn.ConvTranspose2d(32, 32, 3, padding = 1)\n",
    "        self.c7_2 = nn.ConvTranspose2d(32, 32, 3, padding = 1)\n",
    "\n",
    "        self.c8 = nn.Conv2d(32,3,3,padding = 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        c1 = self.c1_1(x)\n",
    "        c1 = F.relu(c1)\n",
    "        c1 = self.c1_2(c1)\n",
    "        c1 = F.relu(c1)\n",
    "        x = self.m1(c1)\n",
    "\n",
    "        c2 = self.c2_1(x)\n",
    "        c2 = F.relu(c2)\n",
    "        c2 = self.c2_2(c2)\n",
    "        c2 = F.relu(c2)\n",
    "        x = self.m2(c2)\n",
    "\n",
    "        c3 = self.c3_1(x)\n",
    "        c3 = F.relu(c3)\n",
    "        c3 = self.c3_2(c3)\n",
    "        c3 = F.relu(c3)\n",
    "        x = self.m3(c3)\n",
    "\n",
    "        c4 = self.c4_1(x)\n",
    "        c4 = F.relu(c4)\n",
    "        c4 = self.c4_2(c4)\n",
    "        c4 = F.relu(c4)\n",
    "\n",
    "        u1 = self.u1(c4)\n",
    "        u1 = F.pad(u1, (0, 1, 0, 1))\n",
    "        c5 = self.c5_1(u1)\n",
    "        c5 = F.relu(c5)\n",
    "        c5 = self.c5_2(c5)\n",
    "        c5 = F.relu(c5)\n",
    "\n",
    "        a1 = torch.add(c5,c3)\n",
    "        u2 = self.u2(a1)\n",
    "        u2 = F.pad(u2, (0, 1, 0, 1))\n",
    "        c6 = self.c6_1(u2)\n",
    "        c6 = F.relu(c6)\n",
    "        c6 = self.c6_2(c6)\n",
    "        c6 = F.relu(c6)\n",
    "\n",
    "        a2 = torch.add(c6,c2)\n",
    "        u3 = self.u3(a2)\n",
    "        u3 = F.pad(u3, (0, 1, 0, 1))\n",
    "        c7 = self.c7_1(u3)\n",
    "        c7 = F.relu(c7)\n",
    "        c7 = self.c7_2(c7)\n",
    "        c7 = F.relu(c7)\n",
    "\n",
    "        a3 = torch.add(c7,c1)\n",
    "        c8 = self.c8(a3)\n",
    "        output = F.sigmoid(c8)\n",
    "\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import random\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def get_device():\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "    return device\n",
    "\n",
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "TWbJYo2r_Wgt",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "8a08f003-4f13-4e3a-c8aa-f1a087dfe2d5",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchsummary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4h/ngfg08zd7_52cd0t57x6dl84k2nxsw/T/ipykernel_31332/3971719495.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchsummary'"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "net = Generator()\n",
    "print(net)\n",
    "summary(net, (3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Generator().to(device)\n",
    "import pytorch_ssim\n",
    "\n",
    "model.eval()\n",
    "criterion = pytorch_ssim.SSIM(window_size = 11)\n",
    "lr = 0.001\n",
    "optimizer= torch.optim.Adam(model.parameters(), lr=lr)\n",
    "net = Generator()\n",
    "batch_size = 16\n",
    "train_generator = maSequence(x_train, y_train, batch_size, Daugmentation)\n",
    "test_generator = maSequence(x_test, y_test, batch_size,Daugmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_function():\n",
    "    \n",
    "    with torch.no_grad():\n",
    "            for batch_x, batch_y in test_generator:\n",
    "                input_image = torch.from_numpy(batch_x).to(torch.float32).to(device)\n",
    "                target_image = torch.from_numpy(batch_y).to(torch.float32).to(device)\n",
    "                outputs = model(input_image.view(-1,3,128,128))\n",
    "                \n",
    "    \n",
    "    loss_eval = criterion(outputs, target_image.view(-1,3,128,128))\n",
    "    return loss_eval.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "PSsvoD7J_jJ_",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading train_data batch: 100%|██████████| 9/9 [00:00<00:00, 135.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename ./converted_256/05000_masked/05827_surgical.png\n",
      "filename ./converted_256/04000_masked/04007_surgical.png\n",
      "filename ./converted_256/03000_masked/03877_surgical.png\n",
      "filename ./converted_256/07000_masked/07221_surgical.png\n",
      "filename ./converted_256/05000_masked/05692_surgical.png\n",
      "filename ./converted_256/07000_masked/07650_surgical.png\n",
      "filename ./converted_256/07000_masked/07380_surgical.png\n",
      "filename ./converted_256/01000_masked/01073_surgical.png\n",
      "filename ./converted_256/04000_masked/04369_surgical.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading train_label batch: 100%|██████████| 9/9 [00:00<00:00, 156.52it/s]\n",
      "/Users/yosua.muliawan/miniconda3/envs/deeplearn_course/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1623459064158/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/Users/yosua.muliawan/miniconda3/envs/deeplearn_course/lib/python3.7/site-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36, 3, 128, 128]) torch.Size([36, 3, 128, 128]) tensor([[[[1.0576e-06, 7.8144e-06, 3.7022e-05, 1.1246e-04, 2.1905e-04,\n",
      "           2.7356e-04, 2.1905e-04, 1.1246e-04, 3.7022e-05, 7.8144e-06,\n",
      "           1.0576e-06],\n",
      "          [7.8144e-06, 5.7741e-05, 2.7356e-04, 8.3101e-04, 1.6186e-03,\n",
      "           2.0214e-03, 1.6186e-03, 8.3101e-04, 2.7356e-04, 5.7741e-05,\n",
      "           7.8144e-06],\n",
      "          [3.7022e-05, 2.7356e-04, 1.2961e-03, 3.9371e-03, 7.6684e-03,\n",
      "           9.5766e-03, 7.6684e-03, 3.9371e-03, 1.2961e-03, 2.7356e-04,\n",
      "           3.7022e-05],\n",
      "          [1.1246e-04, 8.3101e-04, 3.9371e-03, 1.1960e-02, 2.3294e-02,\n",
      "           2.9091e-02, 2.3294e-02, 1.1960e-02, 3.9371e-03, 8.3101e-04,\n",
      "           1.1246e-04],\n",
      "          [2.1905e-04, 1.6186e-03, 7.6684e-03, 2.3294e-02, 4.5371e-02,\n",
      "           5.6662e-02, 4.5371e-02, 2.3294e-02, 7.6684e-03, 1.6186e-03,\n",
      "           2.1905e-04],\n",
      "          [2.7356e-04, 2.0214e-03, 9.5766e-03, 2.9091e-02, 5.6662e-02,\n",
      "           7.0762e-02, 5.6662e-02, 2.9091e-02, 9.5766e-03, 2.0214e-03,\n",
      "           2.7356e-04],\n",
      "          [2.1905e-04, 1.6186e-03, 7.6684e-03, 2.3294e-02, 4.5371e-02,\n",
      "           5.6662e-02, 4.5371e-02, 2.3294e-02, 7.6684e-03, 1.6186e-03,\n",
      "           2.1905e-04],\n",
      "          [1.1246e-04, 8.3101e-04, 3.9371e-03, 1.1960e-02, 2.3294e-02,\n",
      "           2.9091e-02, 2.3294e-02, 1.1960e-02, 3.9371e-03, 8.3101e-04,\n",
      "           1.1246e-04],\n",
      "          [3.7022e-05, 2.7356e-04, 1.2961e-03, 3.9371e-03, 7.6684e-03,\n",
      "           9.5766e-03, 7.6684e-03, 3.9371e-03, 1.2961e-03, 2.7356e-04,\n",
      "           3.7022e-05],\n",
      "          [7.8144e-06, 5.7741e-05, 2.7356e-04, 8.3101e-04, 1.6186e-03,\n",
      "           2.0214e-03, 1.6186e-03, 8.3101e-04, 2.7356e-04, 5.7741e-05,\n",
      "           7.8144e-06],\n",
      "          [1.0576e-06, 7.8144e-06, 3.7022e-05, 1.1246e-04, 2.1905e-04,\n",
      "           2.7356e-04, 2.1905e-04, 1.1246e-04, 3.7022e-05, 7.8144e-06,\n",
      "           1.0576e-06]]],\n",
      "\n",
      "\n",
      "        [[[1.0576e-06, 7.8144e-06, 3.7022e-05, 1.1246e-04, 2.1905e-04,\n",
      "           2.7356e-04, 2.1905e-04, 1.1246e-04, 3.7022e-05, 7.8144e-06,\n",
      "           1.0576e-06],\n",
      "          [7.8144e-06, 5.7741e-05, 2.7356e-04, 8.3101e-04, 1.6186e-03,\n",
      "           2.0214e-03, 1.6186e-03, 8.3101e-04, 2.7356e-04, 5.7741e-05,\n",
      "           7.8144e-06],\n",
      "          [3.7022e-05, 2.7356e-04, 1.2961e-03, 3.9371e-03, 7.6684e-03,\n",
      "           9.5766e-03, 7.6684e-03, 3.9371e-03, 1.2961e-03, 2.7356e-04,\n",
      "           3.7022e-05],\n",
      "          [1.1246e-04, 8.3101e-04, 3.9371e-03, 1.1960e-02, 2.3294e-02,\n",
      "           2.9091e-02, 2.3294e-02, 1.1960e-02, 3.9371e-03, 8.3101e-04,\n",
      "           1.1246e-04],\n",
      "          [2.1905e-04, 1.6186e-03, 7.6684e-03, 2.3294e-02, 4.5371e-02,\n",
      "           5.6662e-02, 4.5371e-02, 2.3294e-02, 7.6684e-03, 1.6186e-03,\n",
      "           2.1905e-04],\n",
      "          [2.7356e-04, 2.0214e-03, 9.5766e-03, 2.9091e-02, 5.6662e-02,\n",
      "           7.0762e-02, 5.6662e-02, 2.9091e-02, 9.5766e-03, 2.0214e-03,\n",
      "           2.7356e-04],\n",
      "          [2.1905e-04, 1.6186e-03, 7.6684e-03, 2.3294e-02, 4.5371e-02,\n",
      "           5.6662e-02, 4.5371e-02, 2.3294e-02, 7.6684e-03, 1.6186e-03,\n",
      "           2.1905e-04],\n",
      "          [1.1246e-04, 8.3101e-04, 3.9371e-03, 1.1960e-02, 2.3294e-02,\n",
      "           2.9091e-02, 2.3294e-02, 1.1960e-02, 3.9371e-03, 8.3101e-04,\n",
      "           1.1246e-04],\n",
      "          [3.7022e-05, 2.7356e-04, 1.2961e-03, 3.9371e-03, 7.6684e-03,\n",
      "           9.5766e-03, 7.6684e-03, 3.9371e-03, 1.2961e-03, 2.7356e-04,\n",
      "           3.7022e-05],\n",
      "          [7.8144e-06, 5.7741e-05, 2.7356e-04, 8.3101e-04, 1.6186e-03,\n",
      "           2.0214e-03, 1.6186e-03, 8.3101e-04, 2.7356e-04, 5.7741e-05,\n",
      "           7.8144e-06],\n",
      "          [1.0576e-06, 7.8144e-06, 3.7022e-05, 1.1246e-04, 2.1905e-04,\n",
      "           2.7356e-04, 2.1905e-04, 1.1246e-04, 3.7022e-05, 7.8144e-06,\n",
      "           1.0576e-06]]],\n",
      "\n",
      "\n",
      "        [[[1.0576e-06, 7.8144e-06, 3.7022e-05, 1.1246e-04, 2.1905e-04,\n",
      "           2.7356e-04, 2.1905e-04, 1.1246e-04, 3.7022e-05, 7.8144e-06,\n",
      "           1.0576e-06],\n",
      "          [7.8144e-06, 5.7741e-05, 2.7356e-04, 8.3101e-04, 1.6186e-03,\n",
      "           2.0214e-03, 1.6186e-03, 8.3101e-04, 2.7356e-04, 5.7741e-05,\n",
      "           7.8144e-06],\n",
      "          [3.7022e-05, 2.7356e-04, 1.2961e-03, 3.9371e-03, 7.6684e-03,\n",
      "           9.5766e-03, 7.6684e-03, 3.9371e-03, 1.2961e-03, 2.7356e-04,\n",
      "           3.7022e-05],\n",
      "          [1.1246e-04, 8.3101e-04, 3.9371e-03, 1.1960e-02, 2.3294e-02,\n",
      "           2.9091e-02, 2.3294e-02, 1.1960e-02, 3.9371e-03, 8.3101e-04,\n",
      "           1.1246e-04],\n",
      "          [2.1905e-04, 1.6186e-03, 7.6684e-03, 2.3294e-02, 4.5371e-02,\n",
      "           5.6662e-02, 4.5371e-02, 2.3294e-02, 7.6684e-03, 1.6186e-03,\n",
      "           2.1905e-04],\n",
      "          [2.7356e-04, 2.0214e-03, 9.5766e-03, 2.9091e-02, 5.6662e-02,\n",
      "           7.0762e-02, 5.6662e-02, 2.9091e-02, 9.5766e-03, 2.0214e-03,\n",
      "           2.7356e-04],\n",
      "          [2.1905e-04, 1.6186e-03, 7.6684e-03, 2.3294e-02, 4.5371e-02,\n",
      "           5.6662e-02, 4.5371e-02, 2.3294e-02, 7.6684e-03, 1.6186e-03,\n",
      "           2.1905e-04],\n",
      "          [1.1246e-04, 8.3101e-04, 3.9371e-03, 1.1960e-02, 2.3294e-02,\n",
      "           2.9091e-02, 2.3294e-02, 1.1960e-02, 3.9371e-03, 8.3101e-04,\n",
      "           1.1246e-04],\n",
      "          [3.7022e-05, 2.7356e-04, 1.2961e-03, 3.9371e-03, 7.6684e-03,\n",
      "           9.5766e-03, 7.6684e-03, 3.9371e-03, 1.2961e-03, 2.7356e-04,\n",
      "           3.7022e-05],\n",
      "          [7.8144e-06, 5.7741e-05, 2.7356e-04, 8.3101e-04, 1.6186e-03,\n",
      "           2.0214e-03, 1.6186e-03, 8.3101e-04, 2.7356e-04, 5.7741e-05,\n",
      "           7.8144e-06],\n",
      "          [1.0576e-06, 7.8144e-06, 3.7022e-05, 1.1246e-04, 2.1905e-04,\n",
      "           2.7356e-04, 2.1905e-04, 1.1246e-04, 3.7022e-05, 7.8144e-06,\n",
      "           1.0576e-06]]]]) 11 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4h/ngfg08zd7_52cd0t57x6dl84k2nxsw/T/ipykernel_31332/1882876196.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearn_course/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearn_course/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_evolution = []\n",
    "epochs = []\n",
    "validate_loss_evolution = []\n",
    "for epoch in range(1,300):\n",
    " \n",
    "    for i, (batch_x, batch_y) in enumerate(train_generator):\n",
    "        \n",
    "        input_image = torch.from_numpy(batch_x).to(torch.float32).to(device)\n",
    "        target_image = torch.from_numpy(batch_y).to(torch.float32).to(device)\n",
    "        \n",
    "        # FORWARD AND BACKWARD PASS\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_image.view(-1,3,128,128))\n",
    "        loss = criterion(outputs, target_image.view(-1,3,128,128))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "           \n",
    "    \n",
    "    if epoch%5 == 0:\n",
    "        validate_loss = eval_function()\n",
    "        print(\"loss = \", loss.item(), \" \", \"validate_loss = \", validate_loss)\n",
    "        loss_evolution.append(loss.item())\n",
    "        validate_loss_evolution.append(validate_loss)\n",
    "        epochs.append(epoch)\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f\"./unmask_encoder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4h/ngfg08zd7_52cd0t57x6dl84k2nxsw/T/ipykernel_31332/4115476235.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "masks = x_test[:10]\n",
    "inputs = torch.tensor(masks).view(-1,3,128,128)\n",
    "device = torch.device('cpu')\n",
    "inputs = torch.Tensor.cpu(inputs)\n",
    "model = model.to(device)\n",
    "nomask_preds = model(inputs).view(-1,128,128,3).detach().numpy()\n",
    "nomask_actuals = y_test[:10]\n",
    "for i in range(10):\n",
    "    plt.subplot(3,10,i+1)\n",
    "    plt.imshow(masks[i])\n",
    "    plt.axis(\"OFF\")\n",
    "    \n",
    "    plt.subplot(3,10,i+11)\n",
    "    plt.imshow(nomask_preds[i])\n",
    "    plt.axis(\"OFF\")\n",
    "    \n",
    "    plt.subplot(3,10,i+21)\n",
    "    plt.imshow(nomask_actuals[i])\n",
    "    plt.axis(\"OFF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4h/ngfg08zd7_52cd0t57x6dl84k2nxsw/T/ipykernel_31332/406230939.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_evolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_loss_evolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"validate loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lower left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(epochs, loss_evolution, label = \"loss\")\n",
    "plt.plot(epochs, validate_loss_evolution, label = \"validate loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CS5260 - Team Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
